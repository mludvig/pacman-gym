{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PacMan-v1 - SageMaker notebook\n",
    "\n",
    "*By Michael Ludvig*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "from sagemaker_job.misc import get_execution_role, wait_for_s3_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find out AWS resources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out S3 bucket\n",
    "sage_session = sagemaker.session.Session()\n",
    "s3_bucket = sage_session.default_bucket()  \n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))\n",
    "\n",
    "# Figure out execution role\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except:\n",
    "    role = get_execution_role()\n",
    "\n",
    "print(\"Using IAM role arn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RL Estimator** - here the training happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local_mode = True\n",
    "estimator_wait = True\n",
    "\n",
    "PRESETS = [\n",
    "#    \"PacMan_A3C\",\n",
    "#    \"PacMan_ACER\",\n",
    "#    \"PacMan_ClippedPPO\",\n",
    "#    \"PacMan_DDQN_BatchRL\",\n",
    "#    \"PacMan_DDQN_BCQ_BatchRL\",\n",
    "#    \"PacMan_DFP\",\n",
    "    \"PacMan_DQN\",\n",
    "#    \"PacMan_Dueling_DDQN\",\n",
    "#    \"PacMan_NEC\",\n",
    "#    \"PacMan_NStepQ\",\n",
    "#    \"PacMan_PAL\",\n",
    "#    \"PacMan_PG\",\n",
    "#    \"PacMan_QR_DQN\",\n",
    "#    \"PacMan_Rainbow\",\n",
    "]\n",
    "\n",
    "if local_mode:\n",
    "    !/bin/bash ./sagemaker_job/setup.sh\n",
    "    spot_kwargs = {}\n",
    "else:\n",
    "    instance_type = \"ml.c5.xlarge\"\n",
    "    spot_kwargs = {\n",
    "        'train_use_spot_instances': True,\n",
    "        'train_max_wait': 1*3600,    # Max time waiting for spot instance\n",
    "        'train_max_run': 1*3600,     # Max training run time\n",
    "    }\n",
    "\n",
    "for preset in PRESETS:\n",
    "    estimator = RLEstimator(entry_point=\"train-coach.py\",\n",
    "                        source_dir=\"sagemaker_job\",\n",
    "                        dependencies=[\"gym_pacman\"],\n",
    "                        toolkit=RLToolkit.COACH,\n",
    "                        toolkit_version='0.11.0',\n",
    "                        framework=RLFramework.MXNET,\n",
    "                        role=role,\n",
    "                        train_instance_type=instance_type if not local_mode else 'local',\n",
    "                        train_instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=preset.replace('_', '-'),\n",
    "                        hyperparameters = {\n",
    "                            \"RLCOACH_PRESET\": preset,\n",
    "                            \"improve_steps\": 10000,  # short training only for testing the next steps\n",
    "                            \"save_model\": 1,\n",
    "                            'rl.agent_params.algorithm.discount': 0.618,\n",
    "                            'rl.agent_params.algorithm.beta_entropy': 0.04,\n",
    "                            'rl.learning_rate': 0.002   # see sagemaker_job/train-coach.py for mapping\n",
    "                        },\n",
    "                        **spot_kwargs,\n",
    "                    )\n",
    "\n",
    "    estimator.fit(wait=estimator_wait)\n",
    "    if not local_mode:\n",
    "        print(\"Job name: {}\".format(estimator._current_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure out the reports names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name=estimator._current_job_name\n",
    "print(\"Job name: {}\".format(job_name))\n",
    "\n",
    "s3_url = \"s3://{}/{}\".format(s3_bucket,job_name)\n",
    "\n",
    "if local_mode:\n",
    "    output_tar_key = \"{}/output.tar.gz\".format(job_name)\n",
    "else:\n",
    "    output_tar_key = \"{}/output/output.tar.gz\".format(job_name)\n",
    "\n",
    "intermediate_folder_key = \"{}/output/intermediate/\".format(job_name)\n",
    "output_url = \"s3://{}/{}\".format(s3_bucket, output_tar_key)\n",
    "intermediate_url = \"s3://{}/{}\".format(s3_bucket, intermediate_folder_key)\n",
    "\n",
    "print(\"S3 job path: {}\".format(s3_url))\n",
    "print(\"Output.tar.gz location: {}\".format(output_url))\n",
    "print(\"Intermediate folder path: {}\".format(intermediate_url))\n",
    "    \n",
    "tmp_dir = \"/tmp/{}\".format(job_name)\n",
    "os.system(\"mkdir {}\".format(tmp_dir))\n",
    "print(\"Create local folder {}\".format(tmp_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot training progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_name = \"worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\"\n",
    "key = os.path.join(intermediate_folder_key, csv_file_name)\n",
    "wait_for_s3_object(s3_bucket, key, tmp_dir, training_job_name=job_name)\n",
    "\n",
    "csv_file = \"{}/{}\".format(tmp_dir, csv_file_name)\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df.dropna(subset=['Training Reward'])\n",
    "\n",
    "x_axis = 'Episode #'\n",
    "y_axis = 'Training Reward'\n",
    "\n",
    "df['group'] = df['Episode #'].floordiv(100)\n",
    "avg = df.groupby('group')['Training Reward'].mean()\n",
    "plt = avg.plot()\n",
    "plt.set_xlabel('Episode x100')\n",
    "plt.set_ylabel('Average Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker Predictor Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.t2.medium',\n",
    "                             entry_point='deploy-mxnet-coach.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing setup\n",
    "\n",
    "Emulate the Gym data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is from gym_pacman/PacMan_V1.py\n",
    "from enum import IntEnum\n",
    "import numpy as np\n",
    "\n",
    "class BoardStatus(IntEnum):\n",
    "    EMPTY = 0\n",
    "    DOT = 1\n",
    "    PACMAN = 2\n",
    "\n",
    "class Action(IntEnum):\n",
    "    UP = 0\n",
    "    DOWN = 1\n",
    "    LEFT = 2\n",
    "    RIGHT = 3\n",
    "\n",
    "def get_cell_value(layer, position):\n",
    "    return layer[position[0]][position[1]]\n",
    "\n",
    "def set_cell_value(layer, position, value):\n",
    "    layer[position[0]][position[1]] = value\n",
    "\n",
    "def build_observation():\n",
    "    return np.stack([\n",
    "            layer_0_board,\n",
    "            layer_1_pacman,\n",
    "    ], axis=2).repeat(axis=0, repeats=repeat_multiplier).repeat(axis=1, repeats=repeat_multiplier)  # scale up the array to prevent \"kernel is bigger than input\" error\n",
    "\n",
    "repeat_multiplier = 4\n",
    "board_size=(5,5)\n",
    "\n",
    "layer_0_board = np.full(board_size, BoardStatus.DOT, dtype=np.int32)\n",
    "layer_1_pacman = np.full(board_size, BoardStatus.EMPTY, dtype=np.int32)\n",
    "#position = np.array([np.random.randint(board_size[0]), np.random.randint(board_size[1])])\n",
    "position = np.array([0, 0])    # PacMan position\n",
    "\n",
    "set_cell_value(layer_0_board, position, BoardStatus.EMPTY)\n",
    "set_cell_value(layer_1_pacman, position, BoardStatus.PACMAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the data in the same format as during training \n",
    "# From gym_pacman/PacMan_v1.py:_get_observation()\n",
    "observation = np.stack([\n",
    "    layer_0_board,\n",
    "    layer_1_pacman,\n",
    "], axis=2).repeat(axis=0, repeats=repeat_multiplier).repeat(axis=1, repeats=repeat_multiplier)\n",
    "# print(repr(layer_0_board))\n",
    "# print(repr(layer_1_pacman))\n",
    "# print(repr(observation))\n",
    "predictor.predict(data = observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
